{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>translated</th>\n",
       "      <th>case_fold</th>\n",
       "      <th>token</th>\n",
       "      <th>stop</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inilah 2 unit Rumah Tapak Jabatan Menteri yang...</td>\n",
       "      <td>Fri Mar 29 11:48:49 +0000 2024</td>\n",
       "      <td>Inilah 2 unit Rumah Tapak Jabatan Menteri yang...</td>\n",
       "      <td>b These are the 2 units of Landed Houses for M...</td>\n",
       "      <td>b these are the  units of landed houses for mi...</td>\n",
       "      <td>['b', 'these', 'are', 'the', 'units', 'of', 'l...</td>\n",
       "      <td>['b', 'units', 'landed', 'houses', 'ministeria...</td>\n",
       "      <td>['b', 'unit', 'land', 'house', 'ministerial', ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alhamdulillah terima kasih berkenan mengunjung...</td>\n",
       "      <td>Fri Mar 29 02:34:41 +0000 2024</td>\n",
       "      <td>Alhamdulillah terima kasih berkenan mengunjung...</td>\n",
       "      <td>b Alhamdulillah thank you for visiting the Ind...</td>\n",
       "      <td>b alhamdulillah thank you for visiting the ind...</td>\n",
       "      <td>['b', 'alhamdulillah', 'thank', 'you', 'for', ...</td>\n",
       "      <td>['b', 'alhamdulillah', 'thank', 'visiting', 'i...</td>\n",
       "      <td>['b', 'alhamdulillah', 'thank', 'visit', 'indo...</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pengamat Kritik 2 Proyek Milik Konglomerat Pen...</td>\n",
       "      <td>Thu Mar 28 23:39:00 +0000 2024</td>\n",
       "      <td>Pengamat Kritik 2 Proyek Milik Konglomerat Pen...</td>\n",
       "      <td>b Observers Criticize 2 Projects Owned by Cong...</td>\n",
       "      <td>b observers criticize  projects owned by congl...</td>\n",
       "      <td>['b', 'observers', 'criticize', 'projects', 'o...</td>\n",
       "      <td>['b', 'observers', 'criticize', 'projects', 'o...</td>\n",
       "      <td>['b', 'observer', 'criticize', 'project', 'own...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow‼️Terlihat dari pinggir jalan Gedung-gedung...</td>\n",
       "      <td>Thu Mar 28 06:04:01 +0000 2024</td>\n",
       "      <td>Wow‼️Terlihat dari pinggir jalan Gedunggedung ...</td>\n",
       "      <td>b Wow Seen from the side of the road towering ...</td>\n",
       "      <td>b wow seen from the side of the road towering ...</td>\n",
       "      <td>['b', 'wow', 'seen', 'from', 'the', 'side', 'o...</td>\n",
       "      <td>['b', 'wow', 'seen', 'side', 'road', 'towering...</td>\n",
       "      <td>['b', 'wow', 'see', 'side', 'road', 'tower', '...</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waktu ngedrone roll off trafo PLN di pelabuhan...</td>\n",
       "      <td>Thu Mar 28 03:03:32 +0000 2024</td>\n",
       "      <td>Waktu ngedrone roll off trafo PLN di pelabuhan...</td>\n",
       "      <td>b When droned to roll off a PLN transformer at...</td>\n",
       "      <td>b when droned to roll off a pln transformer at...</td>\n",
       "      <td>['b', 'when', 'droned', 'to', 'roll', 'off', '...</td>\n",
       "      <td>['b', 'droned', 'roll', 'pln', 'transformer', ...</td>\n",
       "      <td>['b', 'drone', 'roll', 'pln', 'transformer', '...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Usulan DPR tak Ikut Pindah ke IKN Nusantara Di...</td>\n",
       "      <td>Wed Mar 27 03:18:10 +0000 2024</td>\n",
       "      <td>Usulan DPR tak Ikut Pindah ke IKN Nusantara Di...</td>\n",
       "      <td>b DPR s proposal not to participate in moving ...</td>\n",
       "      <td>b dpr s proposal not to participate in moving ...</td>\n",
       "      <td>['b', 'dpr', 's', 'proposal', 'not', 'to', 'pa...</td>\n",
       "      <td>['b', 'dpr', 'proposal', 'participate', 'movin...</td>\n",
       "      <td>['b', 'dpr', 'proposal', 'participate', 'move'...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Suasana Proyek Pembangunan Bandara VVIP IKN ap...</td>\n",
       "      <td>Wed Mar 27 02:48:24 +0000 2024</td>\n",
       "      <td>Suasana Proyek Pembangunan Bandara VVIP IKN ap...</td>\n",
       "      <td>b The atmosphere of the VVIP IKN Airport Devel...</td>\n",
       "      <td>b the atmosphere of the vvip ikn airport devel...</td>\n",
       "      <td>['b', 'the', 'atmosphere', 'of', 'the', 'vvip'...</td>\n",
       "      <td>['b', 'atmosphere', 'vvip', 'ikn', 'airport', ...</td>\n",
       "      <td>['b', 'atmosphere', 'vvip', 'ikn', 'airport', ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Investasi di IKN Nusantara Dinilai Tidak Mengu...</td>\n",
       "      <td>Tue Mar 26 23:39:00 +0000 2024</td>\n",
       "      <td>Investasi di IKN Nusantara Dinilai Tidak Mengu...</td>\n",
       "      <td>b Investment in IKN Nusantara is considered no...</td>\n",
       "      <td>b investment in ikn nusantara is considered no...</td>\n",
       "      <td>['b', 'investment', 'in', 'ikn', 'nusantara', ...</td>\n",
       "      <td>['b', 'investment', 'ikn', 'nusantara', 'consi...</td>\n",
       "      <td>['b', 'investment', 'ikn', 'nusantara', 'consi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.6002</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inilah Hunian ASN 4 yang mana pembangunan nya ...</td>\n",
       "      <td>Tue Mar 26 13:56:24 +0000 2024</td>\n",
       "      <td>Inilah Hunian ASN 4 yang mana pembangunan nya ...</td>\n",
       "      <td>b This is the ASN 4 Residence where constructi...</td>\n",
       "      <td>b this is the asn  residence where constructio...</td>\n",
       "      <td>['b', 'this', 'is', 'the', 'asn', 'residence',...</td>\n",
       "      <td>['b', 'asn', 'residence', 'construction', 'bec...</td>\n",
       "      <td>['b', 'asn', 'residence', 'construction', 'bec...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Investasi di IKN Nusantara Dinilai Tidak Mengu...</td>\n",
       "      <td>Tue Mar 26 11:47:44 +0000 2024</td>\n",
       "      <td>Investasi di IKN Nusantara Dinilai Tidak Mengu...</td>\n",
       "      <td>b Investment in IKN Nusantara is considered no...</td>\n",
       "      <td>b investment in ikn nusantara is considered no...</td>\n",
       "      <td>['b', 'investment', 'in', 'ikn', 'nusantara', ...</td>\n",
       "      <td>['b', 'investment', 'ikn', 'nusantara', 'consi...</td>\n",
       "      <td>['b', 'investment', 'ikn', 'nusantara', 'consi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.6002</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Inilah 2 unit Rumah Tapak Jabatan Menteri yang...   \n",
       "1  Alhamdulillah terima kasih berkenan mengunjung...   \n",
       "2  Pengamat Kritik 2 Proyek Milik Konglomerat Pen...   \n",
       "3  Wow‼️Terlihat dari pinggir jalan Gedung-gedung...   \n",
       "4  Waktu ngedrone roll off trafo PLN di pelabuhan...   \n",
       "5  Usulan DPR tak Ikut Pindah ke IKN Nusantara Di...   \n",
       "6  Suasana Proyek Pembangunan Bandara VVIP IKN ap...   \n",
       "7  Investasi di IKN Nusantara Dinilai Tidak Mengu...   \n",
       "8  Inilah Hunian ASN 4 yang mana pembangunan nya ...   \n",
       "9  Investasi di IKN Nusantara Dinilai Tidak Mengu...   \n",
       "\n",
       "                       created_at  \\\n",
       "0  Fri Mar 29 11:48:49 +0000 2024   \n",
       "1  Fri Mar 29 02:34:41 +0000 2024   \n",
       "2  Thu Mar 28 23:39:00 +0000 2024   \n",
       "3  Thu Mar 28 06:04:01 +0000 2024   \n",
       "4  Thu Mar 28 03:03:32 +0000 2024   \n",
       "5  Wed Mar 27 03:18:10 +0000 2024   \n",
       "6  Wed Mar 27 02:48:24 +0000 2024   \n",
       "7  Tue Mar 26 23:39:00 +0000 2024   \n",
       "8  Tue Mar 26 13:56:24 +0000 2024   \n",
       "9  Tue Mar 26 11:47:44 +0000 2024   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  Inilah 2 unit Rumah Tapak Jabatan Menteri yang...   \n",
       "1  Alhamdulillah terima kasih berkenan mengunjung...   \n",
       "2  Pengamat Kritik 2 Proyek Milik Konglomerat Pen...   \n",
       "3  Wow‼️Terlihat dari pinggir jalan Gedunggedung ...   \n",
       "4  Waktu ngedrone roll off trafo PLN di pelabuhan...   \n",
       "5  Usulan DPR tak Ikut Pindah ke IKN Nusantara Di...   \n",
       "6  Suasana Proyek Pembangunan Bandara VVIP IKN ap...   \n",
       "7  Investasi di IKN Nusantara Dinilai Tidak Mengu...   \n",
       "8  Inilah Hunian ASN 4 yang mana pembangunan nya ...   \n",
       "9  Investasi di IKN Nusantara Dinilai Tidak Mengu...   \n",
       "\n",
       "                                          translated  \\\n",
       "0  b These are the 2 units of Landed Houses for M...   \n",
       "1  b Alhamdulillah thank you for visiting the Ind...   \n",
       "2  b Observers Criticize 2 Projects Owned by Cong...   \n",
       "3  b Wow Seen from the side of the road towering ...   \n",
       "4  b When droned to roll off a PLN transformer at...   \n",
       "5  b DPR s proposal not to participate in moving ...   \n",
       "6  b The atmosphere of the VVIP IKN Airport Devel...   \n",
       "7  b Investment in IKN Nusantara is considered no...   \n",
       "8  b This is the ASN 4 Residence where constructi...   \n",
       "9  b Investment in IKN Nusantara is considered no...   \n",
       "\n",
       "                                           case_fold  \\\n",
       "0  b these are the  units of landed houses for mi...   \n",
       "1  b alhamdulillah thank you for visiting the ind...   \n",
       "2  b observers criticize  projects owned by congl...   \n",
       "3  b wow seen from the side of the road towering ...   \n",
       "4  b when droned to roll off a pln transformer at...   \n",
       "5  b dpr s proposal not to participate in moving ...   \n",
       "6  b the atmosphere of the vvip ikn airport devel...   \n",
       "7  b investment in ikn nusantara is considered no...   \n",
       "8  b this is the asn  residence where constructio...   \n",
       "9  b investment in ikn nusantara is considered no...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['b', 'these', 'are', 'the', 'units', 'of', 'l...   \n",
       "1  ['b', 'alhamdulillah', 'thank', 'you', 'for', ...   \n",
       "2  ['b', 'observers', 'criticize', 'projects', 'o...   \n",
       "3  ['b', 'wow', 'seen', 'from', 'the', 'side', 'o...   \n",
       "4  ['b', 'when', 'droned', 'to', 'roll', 'off', '...   \n",
       "5  ['b', 'dpr', 's', 'proposal', 'not', 'to', 'pa...   \n",
       "6  ['b', 'the', 'atmosphere', 'of', 'the', 'vvip'...   \n",
       "7  ['b', 'investment', 'in', 'ikn', 'nusantara', ...   \n",
       "8  ['b', 'this', 'is', 'the', 'asn', 'residence',...   \n",
       "9  ['b', 'investment', 'in', 'ikn', 'nusantara', ...   \n",
       "\n",
       "                                                stop  \\\n",
       "0  ['b', 'units', 'landed', 'houses', 'ministeria...   \n",
       "1  ['b', 'alhamdulillah', 'thank', 'visiting', 'i...   \n",
       "2  ['b', 'observers', 'criticize', 'projects', 'o...   \n",
       "3  ['b', 'wow', 'seen', 'side', 'road', 'towering...   \n",
       "4  ['b', 'droned', 'roll', 'pln', 'transformer', ...   \n",
       "5  ['b', 'dpr', 'proposal', 'participate', 'movin...   \n",
       "6  ['b', 'atmosphere', 'vvip', 'ikn', 'airport', ...   \n",
       "7  ['b', 'investment', 'ikn', 'nusantara', 'consi...   \n",
       "8  ['b', 'asn', 'residence', 'construction', 'bec...   \n",
       "9  ['b', 'investment', 'ikn', 'nusantara', 'consi...   \n",
       "\n",
       "                                          lemmatized  Positive  Negative  \\\n",
       "0  ['b', 'unit', 'land', 'house', 'ministerial', ...     0.000     0.000   \n",
       "1  ['b', 'alhamdulillah', 'thank', 'visit', 'indo...     0.161     0.000   \n",
       "2  ['b', 'observer', 'criticize', 'project', 'own...     0.141     0.127   \n",
       "3  ['b', 'wow', 'see', 'side', 'road', 'tower', '...     0.132     0.000   \n",
       "4  ['b', 'drone', 'roll', 'pln', 'transformer', '...     0.072     0.000   \n",
       "5  ['b', 'dpr', 'proposal', 'participate', 'move'...     0.000     0.107   \n",
       "6  ['b', 'atmosphere', 'vvip', 'ikn', 'airport', ...     0.000     0.000   \n",
       "7  ['b', 'investment', 'ikn', 'nusantara', 'consi...     0.000     0.246   \n",
       "8  ['b', 'asn', 'residence', 'construction', 'bec...     0.000     0.000   \n",
       "9  ['b', 'investment', 'ikn', 'nusantara', 'consi...     0.000     0.246   \n",
       "\n",
       "   Neutral  Compound Sentiment  \n",
       "0    1.000    0.0000   Neutral  \n",
       "1    0.839    0.6369  Positive  \n",
       "2    0.732    0.0772  Positive  \n",
       "3    0.868    0.5859  Positive  \n",
       "4    0.928    0.3400  Positive  \n",
       "5    0.893   -0.3400  Negative  \n",
       "6    1.000    0.0000   Neutral  \n",
       "7    0.754   -0.6002  Negative  \n",
       "8    1.000    0.0000   Neutral  \n",
       "9    0.754   -0.6002  Negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"output/vader_labelled6.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'cleaned' column contains the text data and 'Sentiment' contains labels\n",
    "texts = df['lemmatized'].astype(str).tolist()\n",
    "labels = df['Sentiment'].tolist()\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=10000)  # Using the top 10,000 words\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Pad the sequences\n",
    "maxlen = 100  # Define the max length of the sequences\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "y = pd.get_dummies(labels).values  # Convert labels to one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=input_length))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))  # Assuming 3 classes for Sentiment\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Average Accuracy: 0.7665211062590975\n",
      "Average Precision: 0.7908813505182789\n",
      "Average Recall: 0.7665211062590975\n",
      "Average F1 Score: 0.7732951884065642\n",
      "Average AUC Score: 0.9011603159963721\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "smote = SMOTE()\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Resample the training data\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train.argmax(axis=1))\n",
    "    y_train_resampled = pd.get_dummies(y_train_resampled).values\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_cnn_model(input_length=maxlen)\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = y_pred.argmax(axis=-1)\n",
    "    y_true = y_test.argmax(axis=-1)\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(y_true, y_pred_classes))\n",
    "    precision_scores.append(precision_score(y_true, y_pred_classes, average='weighted'))\n",
    "    recall_scores.append(recall_score(y_true, y_pred_classes, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_true, y_pred_classes, average='weighted'))\n",
    "    auc_scores.append(roc_auc_score(y_true, y_pred, multi_class='ovr'))\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(accuracy_scores)}')\n",
    "print(f'Average Precision: {np.mean(precision_scores)}')\n",
    "print(f'Average Recall: {np.mean(recall_scores)}')\n",
    "print(f'Average F1 Score: {np.mean(f1_scores)}')\n",
    "print(f'Average AUC Score: {np.mean(auc_scores)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
